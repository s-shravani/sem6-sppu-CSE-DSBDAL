{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analytics 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement Logistic Regression using Python/R to perform classification on Social_Networks_Ads.csv dataset.\n",
    "2. Compute confusion matrix to find TP,FP,TN,FN, Accuracy, Error Rate, Precision, Recall on the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Importing Libraries and Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Social_Network_Ads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15691863</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>15706071</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>15654296</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>15755018</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>15594041</td>\n",
       "      <td>Female</td>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0    15624510    Male   19            19000          0\n",
       "1    15810944    Male   35            20000          0\n",
       "2    15668575  Female   26            43000          0\n",
       "3    15603246  Female   27            57000          0\n",
       "4    15804002    Male   19            76000          0\n",
       "..        ...     ...  ...              ...        ...\n",
       "395  15691863  Female   46            41000          1\n",
       "396  15706071    Male   51            23000          1\n",
       "397  15654296  Female   50            20000          1\n",
       "398  15755018    Male   36            33000          0\n",
       "399  15594041  Female   49            36000          1\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks total size(rows*columns)\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks dimensions of dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User ID', 'Gender', 'Age', 'EstimatedSalary', 'Purchased'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks the columns present\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User ID             int64\n",
       "Gender             object\n",
       "Age                 int64\n",
       "EstimatedSalary     int64\n",
       "Purchased           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks datatype of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   User ID          400 non-null    int64 \n",
      " 1   Gender           400 non-null    object\n",
      " 2   Age              400 non-null    int64 \n",
      " 3   EstimatedSalary  400 non-null    int64 \n",
      " 4   Purchased        400 non-null    int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#prints information of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000e+02</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.569154e+07</td>\n",
       "      <td>37.655000</td>\n",
       "      <td>69742.500000</td>\n",
       "      <td>0.357500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.165832e+04</td>\n",
       "      <td>10.482877</td>\n",
       "      <td>34096.960282</td>\n",
       "      <td>0.479864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.556669e+07</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.562676e+07</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>43000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.569434e+07</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.575036e+07</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>88000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.581524e+07</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User ID         Age  EstimatedSalary   Purchased\n",
       "count  4.000000e+02  400.000000       400.000000  400.000000\n",
       "mean   1.569154e+07   37.655000     69742.500000    0.357500\n",
       "std    7.165832e+04   10.482877     34096.960282    0.479864\n",
       "min    1.556669e+07   18.000000     15000.000000    0.000000\n",
       "25%    1.562676e+07   29.750000     43000.000000    0.000000\n",
       "50%    1.569434e+07   37.000000     70000.000000    0.000000\n",
       "75%    1.575036e+07   46.000000     88000.000000    1.000000\n",
       "max    1.581524e+07   60.000000    150000.000000    1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks initial statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Data Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is split our data into an x-array (which contains the data that we will use to make predictions) and a y-array (which contains the data that we are trying to predict).\n",
    "\n",
    "x: Similar to linear regression, the input array x is a two-dimensional array that contains the independent variables or features of the dataset. Each row in the array represents a single instance or data point, and each column represents a specific feature or attribute. The shape of x would be (n_samples, n_features), where n_samples is the number of data points, and n_features is the number of features.\n",
    "\n",
    "y: The target array y is a one-dimensional array that contains the corresponding target or dependent variable values for each instance in the dataset. In logistic regression, the target array y represents the binary categorical variable, indicating the class membership or the probability of an instance belonging to a particular class. The shape of y would be (n_samples,), matching the number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Independent Variables\n",
    "x = df.iloc[:,[2,3]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    19,  19000],\n",
       "       [    35,  20000],\n",
       "       [    26,  43000],\n",
       "       [    27,  57000],\n",
       "       [    19,  76000],\n",
       "       [    27,  58000],\n",
       "       [    27,  84000],\n",
       "       [    32, 150000],\n",
       "       [    25,  33000],\n",
       "       [    35,  65000],\n",
       "       [    26,  80000],\n",
       "       [    26,  52000],\n",
       "       [    20,  86000],\n",
       "       [    32,  18000],\n",
       "       [    18,  82000],\n",
       "       [    29,  80000],\n",
       "       [    47,  25000],\n",
       "       [    45,  26000],\n",
       "       [    46,  28000],\n",
       "       [    48,  29000],\n",
       "       [    45,  22000],\n",
       "       [    47,  49000],\n",
       "       [    48,  41000],\n",
       "       [    45,  22000],\n",
       "       [    46,  23000],\n",
       "       [    47,  20000],\n",
       "       [    49,  28000],\n",
       "       [    47,  30000],\n",
       "       [    29,  43000],\n",
       "       [    31,  18000],\n",
       "       [    31,  74000],\n",
       "       [    27, 137000],\n",
       "       [    21,  16000],\n",
       "       [    28,  44000],\n",
       "       [    27,  90000],\n",
       "       [    35,  27000],\n",
       "       [    33,  28000],\n",
       "       [    30,  49000],\n",
       "       [    26,  72000],\n",
       "       [    27,  31000],\n",
       "       [    27,  17000],\n",
       "       [    33,  51000],\n",
       "       [    35, 108000],\n",
       "       [    30,  15000],\n",
       "       [    28,  84000],\n",
       "       [    23,  20000],\n",
       "       [    25,  79000],\n",
       "       [    27,  54000],\n",
       "       [    30, 135000],\n",
       "       [    31,  89000],\n",
       "       [    24,  32000],\n",
       "       [    18,  44000],\n",
       "       [    29,  83000],\n",
       "       [    35,  23000],\n",
       "       [    27,  58000],\n",
       "       [    24,  55000],\n",
       "       [    23,  48000],\n",
       "       [    28,  79000],\n",
       "       [    22,  18000],\n",
       "       [    32, 117000],\n",
       "       [    27,  20000],\n",
       "       [    25,  87000],\n",
       "       [    23,  66000],\n",
       "       [    32, 120000],\n",
       "       [    59,  83000],\n",
       "       [    24,  58000],\n",
       "       [    24,  19000],\n",
       "       [    23,  82000],\n",
       "       [    22,  63000],\n",
       "       [    31,  68000],\n",
       "       [    25,  80000],\n",
       "       [    24,  27000],\n",
       "       [    20,  23000],\n",
       "       [    33, 113000],\n",
       "       [    32,  18000],\n",
       "       [    34, 112000],\n",
       "       [    18,  52000],\n",
       "       [    22,  27000],\n",
       "       [    28,  87000],\n",
       "       [    26,  17000],\n",
       "       [    30,  80000],\n",
       "       [    39,  42000],\n",
       "       [    20,  49000],\n",
       "       [    35,  88000],\n",
       "       [    30,  62000],\n",
       "       [    31, 118000],\n",
       "       [    24,  55000],\n",
       "       [    28,  85000],\n",
       "       [    26,  81000],\n",
       "       [    35,  50000],\n",
       "       [    22,  81000],\n",
       "       [    30, 116000],\n",
       "       [    26,  15000],\n",
       "       [    29,  28000],\n",
       "       [    29,  83000],\n",
       "       [    35,  44000],\n",
       "       [    35,  25000],\n",
       "       [    28, 123000],\n",
       "       [    35,  73000],\n",
       "       [    28,  37000],\n",
       "       [    27,  88000],\n",
       "       [    28,  59000],\n",
       "       [    32,  86000],\n",
       "       [    33, 149000],\n",
       "       [    19,  21000],\n",
       "       [    21,  72000],\n",
       "       [    26,  35000],\n",
       "       [    27,  89000],\n",
       "       [    26,  86000],\n",
       "       [    38,  80000],\n",
       "       [    39,  71000],\n",
       "       [    37,  71000],\n",
       "       [    38,  61000],\n",
       "       [    37,  55000],\n",
       "       [    42,  80000],\n",
       "       [    40,  57000],\n",
       "       [    35,  75000],\n",
       "       [    36,  52000],\n",
       "       [    40,  59000],\n",
       "       [    41,  59000],\n",
       "       [    36,  75000],\n",
       "       [    37,  72000],\n",
       "       [    40,  75000],\n",
       "       [    35,  53000],\n",
       "       [    41,  51000],\n",
       "       [    39,  61000],\n",
       "       [    42,  65000],\n",
       "       [    26,  32000],\n",
       "       [    30,  17000],\n",
       "       [    26,  84000],\n",
       "       [    31,  58000],\n",
       "       [    33,  31000],\n",
       "       [    30,  87000],\n",
       "       [    21,  68000],\n",
       "       [    28,  55000],\n",
       "       [    23,  63000],\n",
       "       [    20,  82000],\n",
       "       [    30, 107000],\n",
       "       [    28,  59000],\n",
       "       [    19,  25000],\n",
       "       [    19,  85000],\n",
       "       [    18,  68000],\n",
       "       [    35,  59000],\n",
       "       [    30,  89000],\n",
       "       [    34,  25000],\n",
       "       [    24,  89000],\n",
       "       [    27,  96000],\n",
       "       [    41,  30000],\n",
       "       [    29,  61000],\n",
       "       [    20,  74000],\n",
       "       [    26,  15000],\n",
       "       [    41,  45000],\n",
       "       [    31,  76000],\n",
       "       [    36,  50000],\n",
       "       [    40,  47000],\n",
       "       [    31,  15000],\n",
       "       [    46,  59000],\n",
       "       [    29,  75000],\n",
       "       [    26,  30000],\n",
       "       [    32, 135000],\n",
       "       [    32, 100000],\n",
       "       [    25,  90000],\n",
       "       [    37,  33000],\n",
       "       [    35,  38000],\n",
       "       [    33,  69000],\n",
       "       [    18,  86000],\n",
       "       [    22,  55000],\n",
       "       [    35,  71000],\n",
       "       [    29, 148000],\n",
       "       [    29,  47000],\n",
       "       [    21,  88000],\n",
       "       [    34, 115000],\n",
       "       [    26, 118000],\n",
       "       [    34,  43000],\n",
       "       [    34,  72000],\n",
       "       [    23,  28000],\n",
       "       [    35,  47000],\n",
       "       [    25,  22000],\n",
       "       [    24,  23000],\n",
       "       [    31,  34000],\n",
       "       [    26,  16000],\n",
       "       [    31,  71000],\n",
       "       [    32, 117000],\n",
       "       [    33,  43000],\n",
       "       [    33,  60000],\n",
       "       [    31,  66000],\n",
       "       [    20,  82000],\n",
       "       [    33,  41000],\n",
       "       [    35,  72000],\n",
       "       [    28,  32000],\n",
       "       [    24,  84000],\n",
       "       [    19,  26000],\n",
       "       [    29,  43000],\n",
       "       [    19,  70000],\n",
       "       [    28,  89000],\n",
       "       [    34,  43000],\n",
       "       [    30,  79000],\n",
       "       [    20,  36000],\n",
       "       [    26,  80000],\n",
       "       [    35,  22000],\n",
       "       [    35,  39000],\n",
       "       [    49,  74000],\n",
       "       [    39, 134000],\n",
       "       [    41,  71000],\n",
       "       [    58, 101000],\n",
       "       [    47,  47000],\n",
       "       [    55, 130000],\n",
       "       [    52, 114000],\n",
       "       [    40, 142000],\n",
       "       [    46,  22000],\n",
       "       [    48,  96000],\n",
       "       [    52, 150000],\n",
       "       [    59,  42000],\n",
       "       [    35,  58000],\n",
       "       [    47,  43000],\n",
       "       [    60, 108000],\n",
       "       [    49,  65000],\n",
       "       [    40,  78000],\n",
       "       [    46,  96000],\n",
       "       [    59, 143000],\n",
       "       [    41,  80000],\n",
       "       [    35,  91000],\n",
       "       [    37, 144000],\n",
       "       [    60, 102000],\n",
       "       [    35,  60000],\n",
       "       [    37,  53000],\n",
       "       [    36, 126000],\n",
       "       [    56, 133000],\n",
       "       [    40,  72000],\n",
       "       [    42,  80000],\n",
       "       [    35, 147000],\n",
       "       [    39,  42000],\n",
       "       [    40, 107000],\n",
       "       [    49,  86000],\n",
       "       [    38, 112000],\n",
       "       [    46,  79000],\n",
       "       [    40,  57000],\n",
       "       [    37,  80000],\n",
       "       [    46,  82000],\n",
       "       [    53, 143000],\n",
       "       [    42, 149000],\n",
       "       [    38,  59000],\n",
       "       [    50,  88000],\n",
       "       [    56, 104000],\n",
       "       [    41,  72000],\n",
       "       [    51, 146000],\n",
       "       [    35,  50000],\n",
       "       [    57, 122000],\n",
       "       [    41,  52000],\n",
       "       [    35,  97000],\n",
       "       [    44,  39000],\n",
       "       [    37,  52000],\n",
       "       [    48, 134000],\n",
       "       [    37, 146000],\n",
       "       [    50,  44000],\n",
       "       [    52,  90000],\n",
       "       [    41,  72000],\n",
       "       [    40,  57000],\n",
       "       [    58,  95000],\n",
       "       [    45, 131000],\n",
       "       [    35,  77000],\n",
       "       [    36, 144000],\n",
       "       [    55, 125000],\n",
       "       [    35,  72000],\n",
       "       [    48,  90000],\n",
       "       [    42, 108000],\n",
       "       [    40,  75000],\n",
       "       [    37,  74000],\n",
       "       [    47, 144000],\n",
       "       [    40,  61000],\n",
       "       [    43, 133000],\n",
       "       [    59,  76000],\n",
       "       [    60,  42000],\n",
       "       [    39, 106000],\n",
       "       [    57,  26000],\n",
       "       [    57,  74000],\n",
       "       [    38,  71000],\n",
       "       [    49,  88000],\n",
       "       [    52,  38000],\n",
       "       [    50,  36000],\n",
       "       [    59,  88000],\n",
       "       [    35,  61000],\n",
       "       [    37,  70000],\n",
       "       [    52,  21000],\n",
       "       [    48, 141000],\n",
       "       [    37,  93000],\n",
       "       [    37,  62000],\n",
       "       [    48, 138000],\n",
       "       [    41,  79000],\n",
       "       [    37,  78000],\n",
       "       [    39, 134000],\n",
       "       [    49,  89000],\n",
       "       [    55,  39000],\n",
       "       [    37,  77000],\n",
       "       [    35,  57000],\n",
       "       [    36,  63000],\n",
       "       [    42,  73000],\n",
       "       [    43, 112000],\n",
       "       [    45,  79000],\n",
       "       [    46, 117000],\n",
       "       [    58,  38000],\n",
       "       [    48,  74000],\n",
       "       [    37, 137000],\n",
       "       [    37,  79000],\n",
       "       [    40,  60000],\n",
       "       [    42,  54000],\n",
       "       [    51, 134000],\n",
       "       [    47, 113000],\n",
       "       [    36, 125000],\n",
       "       [    38,  50000],\n",
       "       [    42,  70000],\n",
       "       [    39,  96000],\n",
       "       [    38,  50000],\n",
       "       [    49, 141000],\n",
       "       [    39,  79000],\n",
       "       [    39,  75000],\n",
       "       [    54, 104000],\n",
       "       [    35,  55000],\n",
       "       [    45,  32000],\n",
       "       [    36,  60000],\n",
       "       [    52, 138000],\n",
       "       [    53,  82000],\n",
       "       [    41,  52000],\n",
       "       [    48,  30000],\n",
       "       [    48, 131000],\n",
       "       [    41,  60000],\n",
       "       [    41,  72000],\n",
       "       [    42,  75000],\n",
       "       [    36, 118000],\n",
       "       [    47, 107000],\n",
       "       [    38,  51000],\n",
       "       [    48, 119000],\n",
       "       [    42,  65000],\n",
       "       [    40,  65000],\n",
       "       [    57,  60000],\n",
       "       [    36,  54000],\n",
       "       [    58, 144000],\n",
       "       [    35,  79000],\n",
       "       [    38,  55000],\n",
       "       [    39, 122000],\n",
       "       [    53, 104000],\n",
       "       [    35,  75000],\n",
       "       [    38,  65000],\n",
       "       [    47,  51000],\n",
       "       [    47, 105000],\n",
       "       [    41,  63000],\n",
       "       [    53,  72000],\n",
       "       [    54, 108000],\n",
       "       [    39,  77000],\n",
       "       [    38,  61000],\n",
       "       [    38, 113000],\n",
       "       [    37,  75000],\n",
       "       [    42,  90000],\n",
       "       [    37,  57000],\n",
       "       [    36,  99000],\n",
       "       [    60,  34000],\n",
       "       [    54,  70000],\n",
       "       [    41,  72000],\n",
       "       [    40,  71000],\n",
       "       [    42,  54000],\n",
       "       [    43, 129000],\n",
       "       [    53,  34000],\n",
       "       [    47,  50000],\n",
       "       [    42,  79000],\n",
       "       [    42, 104000],\n",
       "       [    59,  29000],\n",
       "       [    58,  47000],\n",
       "       [    46,  88000],\n",
       "       [    38,  71000],\n",
       "       [    54,  26000],\n",
       "       [    60,  46000],\n",
       "       [    60,  83000],\n",
       "       [    39,  73000],\n",
       "       [    59, 130000],\n",
       "       [    37,  80000],\n",
       "       [    46,  32000],\n",
       "       [    46,  74000],\n",
       "       [    42,  53000],\n",
       "       [    41,  87000],\n",
       "       [    58,  23000],\n",
       "       [    42,  64000],\n",
       "       [    48,  33000],\n",
       "       [    44, 139000],\n",
       "       [    49,  28000],\n",
       "       [    57,  33000],\n",
       "       [    56,  60000],\n",
       "       [    49,  39000],\n",
       "       [    39,  71000],\n",
       "       [    47,  34000],\n",
       "       [    48,  35000],\n",
       "       [    48,  33000],\n",
       "       [    47,  23000],\n",
       "       [    45,  45000],\n",
       "       [    60,  42000],\n",
       "       [    39,  59000],\n",
       "       [    46,  41000],\n",
       "       [    51,  23000],\n",
       "       [    50,  20000],\n",
       "       [    36,  33000],\n",
       "       [    49,  36000]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Dependent Variables\n",
    "y = df.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Splitting the dataset into 75% training & 25% testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, the dataset is typically divided into two subsets: the training set and the test set. These subsets are commonly denoted as x_train and x_test, respectively.\n",
    "\n",
    "x_train: This is the subset of the dataset that is used for training the machine learning model. It contains the input features (independent variables) that are used to learn the underlying patterns and relationships in the data.\n",
    "\n",
    "x_test: This is the subset of the dataset that is used for evaluating the trained model's performance. It also contains the input features, but these data points are not used during the training phase. Instead, they are used to assess how well the model can generalize to unseen data.\n",
    "When training a model, the ultimate goal is to make predictions on new, unseen data points. To evaluate the model's performance, we need to compare its predictions to the true values of the target variable for the test set. Therefore, we also have a corresponding set of target variable values, typically denoted as y_test.\n",
    "\n",
    "In summary, x_train and x_test represent the input features used for training and evaluating the model, respectively. y_test is the corresponding set of true target variable values for the test set, and y_pred is the predicted target variable values generated by the trained model when applied to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data set into training data and test data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,train_size=0.75,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    44,  39000],\n",
       "       [    32, 120000],\n",
       "       [    38,  50000],\n",
       "       [    32, 135000],\n",
       "       [    52,  21000],\n",
       "       [    53, 104000],\n",
       "       [    39,  42000],\n",
       "       [    38,  61000],\n",
       "       [    36,  50000],\n",
       "       [    36,  63000],\n",
       "       [    35,  25000],\n",
       "       [    35,  50000],\n",
       "       [    42,  73000],\n",
       "       [    47,  49000],\n",
       "       [    59,  29000],\n",
       "       [    49,  65000],\n",
       "       [    45, 131000],\n",
       "       [    31,  89000],\n",
       "       [    46,  82000],\n",
       "       [    47,  51000],\n",
       "       [    26,  15000],\n",
       "       [    60, 102000],\n",
       "       [    38, 112000],\n",
       "       [    40, 107000],\n",
       "       [    42,  53000],\n",
       "       [    35,  59000],\n",
       "       [    48,  41000],\n",
       "       [    48, 134000],\n",
       "       [    38, 113000],\n",
       "       [    29, 148000],\n",
       "       [    26,  15000],\n",
       "       [    60,  42000],\n",
       "       [    24,  19000],\n",
       "       [    42, 149000],\n",
       "       [    46,  96000],\n",
       "       [    28,  59000],\n",
       "       [    39,  96000],\n",
       "       [    28,  89000],\n",
       "       [    41,  72000],\n",
       "       [    45,  26000],\n",
       "       [    33,  69000],\n",
       "       [    20,  82000],\n",
       "       [    31,  74000],\n",
       "       [    42,  80000],\n",
       "       [    35,  72000],\n",
       "       [    33, 149000],\n",
       "       [    40,  71000],\n",
       "       [    51, 146000],\n",
       "       [    46,  79000],\n",
       "       [    35,  75000],\n",
       "       [    38,  51000],\n",
       "       [    36,  75000],\n",
       "       [    37,  78000],\n",
       "       [    38,  61000],\n",
       "       [    60, 108000],\n",
       "       [    20,  82000],\n",
       "       [    57,  74000],\n",
       "       [    42,  65000],\n",
       "       [    26,  80000],\n",
       "       [    46, 117000],\n",
       "       [    35,  61000],\n",
       "       [    21,  68000],\n",
       "       [    28,  44000],\n",
       "       [    41,  87000],\n",
       "       [    37,  33000],\n",
       "       [    27,  90000],\n",
       "       [    39,  42000],\n",
       "       [    28, 123000],\n",
       "       [    31, 118000],\n",
       "       [    25,  87000],\n",
       "       [    35,  71000],\n",
       "       [    37,  70000],\n",
       "       [    35,  39000],\n",
       "       [    47,  23000],\n",
       "       [    35, 147000],\n",
       "       [    48, 138000],\n",
       "       [    26,  86000],\n",
       "       [    25,  79000],\n",
       "       [    52, 138000],\n",
       "       [    51,  23000],\n",
       "       [    35,  60000],\n",
       "       [    33, 113000],\n",
       "       [    30, 107000],\n",
       "       [    48,  33000],\n",
       "       [    41,  80000],\n",
       "       [    48,  96000],\n",
       "       [    31,  18000],\n",
       "       [    31,  71000],\n",
       "       [    43, 129000],\n",
       "       [    59,  76000],\n",
       "       [    18,  44000],\n",
       "       [    36, 118000],\n",
       "       [    42,  90000],\n",
       "       [    47,  30000],\n",
       "       [    26,  43000],\n",
       "       [    40,  78000],\n",
       "       [    46,  59000],\n",
       "       [    59,  42000],\n",
       "       [    46,  74000],\n",
       "       [    35,  91000],\n",
       "       [    28,  59000],\n",
       "       [    40,  57000],\n",
       "       [    59, 143000],\n",
       "       [    57,  26000],\n",
       "       [    52,  38000],\n",
       "       [    47, 113000],\n",
       "       [    53, 143000],\n",
       "       [    35,  27000],\n",
       "       [    58, 101000],\n",
       "       [    45,  45000],\n",
       "       [    23,  82000],\n",
       "       [    46,  23000],\n",
       "       [    42,  65000],\n",
       "       [    28,  84000],\n",
       "       [    38,  59000],\n",
       "       [    26,  84000],\n",
       "       [    29,  28000],\n",
       "       [    37,  71000],\n",
       "       [    22,  55000],\n",
       "       [    48,  35000],\n",
       "       [    49,  28000],\n",
       "       [    38,  65000],\n",
       "       [    27,  17000],\n",
       "       [    46,  28000],\n",
       "       [    48, 141000],\n",
       "       [    26,  17000],\n",
       "       [    35,  97000],\n",
       "       [    39,  59000],\n",
       "       [    24,  27000],\n",
       "       [    32,  18000],\n",
       "       [    46,  88000],\n",
       "       [    35,  58000],\n",
       "       [    56,  60000],\n",
       "       [    47,  34000],\n",
       "       [    40,  72000],\n",
       "       [    32, 100000],\n",
       "       [    19,  21000],\n",
       "       [    25,  90000],\n",
       "       [    35,  88000],\n",
       "       [    28,  32000],\n",
       "       [    50,  20000],\n",
       "       [    40,  59000],\n",
       "       [    50,  44000],\n",
       "       [    35,  72000],\n",
       "       [    40, 142000],\n",
       "       [    46,  32000],\n",
       "       [    39,  71000],\n",
       "       [    20,  74000],\n",
       "       [    29,  75000],\n",
       "       [    31,  76000],\n",
       "       [    47,  25000],\n",
       "       [    40,  61000],\n",
       "       [    34, 112000],\n",
       "       [    38,  80000],\n",
       "       [    42,  75000],\n",
       "       [    47,  47000],\n",
       "       [    39,  75000],\n",
       "       [    19,  25000],\n",
       "       [    37,  80000],\n",
       "       [    36,  60000],\n",
       "       [    41,  52000],\n",
       "       [    36, 125000],\n",
       "       [    48,  29000],\n",
       "       [    36, 126000],\n",
       "       [    51, 134000],\n",
       "       [    27,  57000],\n",
       "       [    38,  71000],\n",
       "       [    39,  61000],\n",
       "       [    22,  27000],\n",
       "       [    33,  60000],\n",
       "       [    48,  74000],\n",
       "       [    58,  23000],\n",
       "       [    53,  72000],\n",
       "       [    32, 117000],\n",
       "       [    54,  70000],\n",
       "       [    30,  80000],\n",
       "       [    58,  95000],\n",
       "       [    26,  52000],\n",
       "       [    45,  79000],\n",
       "       [    24,  55000],\n",
       "       [    40,  75000],\n",
       "       [    33,  28000],\n",
       "       [    44, 139000],\n",
       "       [    22,  18000],\n",
       "       [    33,  51000],\n",
       "       [    43, 133000],\n",
       "       [    24,  32000],\n",
       "       [    46,  22000],\n",
       "       [    35,  55000],\n",
       "       [    54, 104000],\n",
       "       [    48, 119000],\n",
       "       [    35,  53000],\n",
       "       [    37, 144000],\n",
       "       [    23,  66000],\n",
       "       [    37, 137000],\n",
       "       [    31,  58000],\n",
       "       [    33,  41000],\n",
       "       [    45,  22000],\n",
       "       [    30,  15000],\n",
       "       [    19,  19000],\n",
       "       [    49,  74000],\n",
       "       [    39, 122000],\n",
       "       [    35,  73000],\n",
       "       [    39,  71000],\n",
       "       [    24,  23000],\n",
       "       [    41,  72000],\n",
       "       [    29,  83000],\n",
       "       [    54,  26000],\n",
       "       [    35,  44000],\n",
       "       [    37,  75000],\n",
       "       [    29,  47000],\n",
       "       [    31,  68000],\n",
       "       [    42,  54000],\n",
       "       [    30, 135000],\n",
       "       [    52, 114000],\n",
       "       [    50,  36000],\n",
       "       [    56, 133000],\n",
       "       [    29,  61000],\n",
       "       [    30,  89000],\n",
       "       [    26,  16000],\n",
       "       [    33,  31000],\n",
       "       [    41,  72000],\n",
       "       [    36,  33000],\n",
       "       [    55, 125000],\n",
       "       [    48, 131000],\n",
       "       [    41,  71000],\n",
       "       [    30,  62000],\n",
       "       [    37,  72000],\n",
       "       [    41,  63000],\n",
       "       [    58,  47000],\n",
       "       [    30, 116000],\n",
       "       [    20,  49000],\n",
       "       [    37,  74000],\n",
       "       [    41,  59000],\n",
       "       [    49,  89000],\n",
       "       [    28,  79000],\n",
       "       [    53,  82000],\n",
       "       [    40,  57000],\n",
       "       [    60,  34000],\n",
       "       [    35, 108000],\n",
       "       [    21,  72000],\n",
       "       [    38,  71000],\n",
       "       [    39, 106000],\n",
       "       [    37,  57000],\n",
       "       [    26,  72000],\n",
       "       [    35,  23000],\n",
       "       [    54, 108000],\n",
       "       [    30,  17000],\n",
       "       [    39, 134000],\n",
       "       [    29,  43000],\n",
       "       [    33,  43000],\n",
       "       [    35,  38000],\n",
       "       [    41,  45000],\n",
       "       [    41,  72000],\n",
       "       [    39, 134000],\n",
       "       [    27, 137000],\n",
       "       [    21,  16000],\n",
       "       [    26,  32000],\n",
       "       [    31,  66000],\n",
       "       [    39,  73000],\n",
       "       [    41,  79000],\n",
       "       [    47,  50000],\n",
       "       [    41,  30000],\n",
       "       [    37,  93000],\n",
       "       [    60,  46000],\n",
       "       [    25,  22000],\n",
       "       [    28,  37000],\n",
       "       [    38,  55000],\n",
       "       [    36,  54000],\n",
       "       [    20,  36000],\n",
       "       [    56, 104000],\n",
       "       [    40,  57000],\n",
       "       [    42, 108000],\n",
       "       [    20,  23000],\n",
       "       [    40,  65000],\n",
       "       [    47,  20000],\n",
       "       [    18,  86000],\n",
       "       [    35,  79000],\n",
       "       [    57,  33000],\n",
       "       [    34,  72000],\n",
       "       [    49,  39000],\n",
       "       [    27,  31000],\n",
       "       [    19,  70000],\n",
       "       [    39,  79000],\n",
       "       [    26,  81000],\n",
       "       [    25,  80000],\n",
       "       [    28,  85000],\n",
       "       [    55,  39000],\n",
       "       [    50,  88000],\n",
       "       [    49,  88000],\n",
       "       [    52, 150000],\n",
       "       [    35,  65000],\n",
       "       [    42,  54000],\n",
       "       [    34,  43000],\n",
       "       [    37,  52000],\n",
       "       [    48,  30000],\n",
       "       [    29,  43000],\n",
       "       [    36,  52000],\n",
       "       [    27,  54000],\n",
       "       [    26, 118000]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    30,  87000],\n",
       "       [    38,  50000],\n",
       "       [    35,  75000],\n",
       "       [    30,  79000],\n",
       "       [    35,  50000],\n",
       "       [    27,  20000],\n",
       "       [    31,  15000],\n",
       "       [    36, 144000],\n",
       "       [    18,  68000],\n",
       "       [    47,  43000],\n",
       "       [    30,  49000],\n",
       "       [    28,  55000],\n",
       "       [    37,  55000],\n",
       "       [    39,  77000],\n",
       "       [    20,  86000],\n",
       "       [    32, 117000],\n",
       "       [    37,  77000],\n",
       "       [    19,  85000],\n",
       "       [    55, 130000],\n",
       "       [    35,  22000],\n",
       "       [    35,  47000],\n",
       "       [    47, 144000],\n",
       "       [    41,  51000],\n",
       "       [    47, 105000],\n",
       "       [    23,  28000],\n",
       "       [    49, 141000],\n",
       "       [    28,  87000],\n",
       "       [    29,  80000],\n",
       "       [    37,  62000],\n",
       "       [    32,  86000],\n",
       "       [    21,  88000],\n",
       "       [    37,  79000],\n",
       "       [    57,  60000],\n",
       "       [    37,  53000],\n",
       "       [    24,  58000],\n",
       "       [    18,  52000],\n",
       "       [    22,  81000],\n",
       "       [    34,  43000],\n",
       "       [    31,  34000],\n",
       "       [    49,  36000],\n",
       "       [    27,  88000],\n",
       "       [    41,  52000],\n",
       "       [    27,  84000],\n",
       "       [    35,  20000],\n",
       "       [    43, 112000],\n",
       "       [    27,  58000],\n",
       "       [    37,  80000],\n",
       "       [    52,  90000],\n",
       "       [    26,  30000],\n",
       "       [    49,  86000],\n",
       "       [    57, 122000],\n",
       "       [    34,  25000],\n",
       "       [    35,  57000],\n",
       "       [    34, 115000],\n",
       "       [    59,  88000],\n",
       "       [    45,  32000],\n",
       "       [    29,  83000],\n",
       "       [    26,  80000],\n",
       "       [    49,  28000],\n",
       "       [    23,  20000],\n",
       "       [    32,  18000],\n",
       "       [    60,  42000],\n",
       "       [    19,  76000],\n",
       "       [    36,  99000],\n",
       "       [    19,  26000],\n",
       "       [    60,  83000],\n",
       "       [    24,  89000],\n",
       "       [    27,  58000],\n",
       "       [    40,  47000],\n",
       "       [    42,  70000],\n",
       "       [    32, 150000],\n",
       "       [    35,  77000],\n",
       "       [    22,  63000],\n",
       "       [    45,  22000],\n",
       "       [    27,  89000],\n",
       "       [    18,  82000],\n",
       "       [    42,  79000],\n",
       "       [    40,  60000],\n",
       "       [    53,  34000],\n",
       "       [    47, 107000],\n",
       "       [    58, 144000],\n",
       "       [    59,  83000],\n",
       "       [    24,  55000],\n",
       "       [    26,  35000],\n",
       "       [    58,  38000],\n",
       "       [    42,  80000],\n",
       "       [    40,  75000],\n",
       "       [    59, 130000],\n",
       "       [    46,  41000],\n",
       "       [    41,  60000],\n",
       "       [    42,  64000],\n",
       "       [    37, 146000],\n",
       "       [    23,  48000],\n",
       "       [    25,  33000],\n",
       "       [    24,  84000],\n",
       "       [    27,  96000],\n",
       "       [    23,  63000],\n",
       "       [    48,  33000],\n",
       "       [    48,  90000],\n",
       "       [    42, 104000]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Data Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In logistic regression, we will do feature scaling because we want accurate result of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of standardization is to ensure that the features have similar scales and distributions, which can be beneficial for certain machine learning algorithms, particularly those that rely on distance calculations or gradient descent optimization. By transforming the features, you can make them have zero mean and unit variance, which can help in improving the model's performance and convergence.\n",
    "\n",
    "However, the target variable, usually denoted as y, does not need to be transformed because it represents the variable we are trying to predict. The model's goal is to make accurate predictions for the target variable based on the provided features. Transforming the target variable wouldn't make sense as it would change the actual values you are trying to predict.\n",
    "\n",
    "So, during the train-test split, you apply the transformation only to the features (x_train and x_test) to ensure that they have similar scales and distributions. The target variable (y_train and y_test) remains untouched as it is used for evaluating the model's performance and making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_x = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sc_x.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58164944, -0.88670699],\n",
       "       [-0.60673761,  1.46173768],\n",
       "       [-0.01254409, -0.5677824 ],\n",
       "       [-0.60673761,  1.89663484],\n",
       "       [ 1.37390747, -1.40858358],\n",
       "       [ 1.47293972,  0.99784738],\n",
       "       [ 0.08648817, -0.79972756],\n",
       "       [-0.01254409, -0.24885782],\n",
       "       [-0.21060859, -0.5677824 ],\n",
       "       [-0.21060859, -0.19087153],\n",
       "       [-0.30964085, -1.29261101],\n",
       "       [-0.30964085, -0.5677824 ],\n",
       "       [ 0.38358493,  0.09905991],\n",
       "       [ 0.8787462 , -0.59677555],\n",
       "       [ 2.06713324, -1.17663843],\n",
       "       [ 1.07681071, -0.13288524],\n",
       "       [ 0.68068169,  1.78066227],\n",
       "       [-0.70576986,  0.56295021],\n",
       "       [ 0.77971394,  0.35999821],\n",
       "       [ 0.8787462 , -0.53878926],\n",
       "       [-1.20093113, -1.58254245],\n",
       "       [ 2.1661655 ,  0.93986109],\n",
       "       [-0.01254409,  1.22979253],\n",
       "       [ 0.18552042,  1.08482681],\n",
       "       [ 0.38358493, -0.48080297],\n",
       "       [-0.30964085, -0.30684411],\n",
       "       [ 0.97777845, -0.8287207 ],\n",
       "       [ 0.97777845,  1.8676417 ],\n",
       "       [-0.01254409,  1.25878567],\n",
       "       [-0.90383437,  2.27354572],\n",
       "       [-1.20093113, -1.58254245],\n",
       "       [ 2.1661655 , -0.79972756],\n",
       "       [-1.39899564, -1.46656987],\n",
       "       [ 0.38358493,  2.30253886],\n",
       "       [ 0.77971394,  0.76590222],\n",
       "       [-1.00286662, -0.30684411],\n",
       "       [ 0.08648817,  0.76590222],\n",
       "       [-1.00286662,  0.56295021],\n",
       "       [ 0.28455268,  0.07006676],\n",
       "       [ 0.68068169, -1.26361786],\n",
       "       [-0.50770535, -0.01691267],\n",
       "       [-1.79512465,  0.35999821],\n",
       "       [-0.70576986,  0.12805305],\n",
       "       [ 0.38358493,  0.30201192],\n",
       "       [-0.30964085,  0.07006676],\n",
       "       [-0.50770535,  2.30253886],\n",
       "       [ 0.18552042,  0.04107362],\n",
       "       [ 1.27487521,  2.21555943],\n",
       "       [ 0.77971394,  0.27301877],\n",
       "       [-0.30964085,  0.1570462 ],\n",
       "       [-0.01254409, -0.53878926],\n",
       "       [-0.21060859,  0.1570462 ],\n",
       "       [-0.11157634,  0.24402563],\n",
       "       [-0.01254409, -0.24885782],\n",
       "       [ 2.1661655 ,  1.11381995],\n",
       "       [-1.79512465,  0.35999821],\n",
       "       [ 1.86906873,  0.12805305],\n",
       "       [ 0.38358493, -0.13288524],\n",
       "       [-1.20093113,  0.30201192],\n",
       "       [ 0.77971394,  1.37475825],\n",
       "       [-0.30964085, -0.24885782],\n",
       "       [-1.6960924 , -0.04590581],\n",
       "       [-1.00286662, -0.74174127],\n",
       "       [ 0.28455268,  0.50496393],\n",
       "       [-0.11157634, -1.06066585],\n",
       "       [-1.10189888,  0.59194336],\n",
       "       [ 0.08648817, -0.79972756],\n",
       "       [-1.00286662,  1.54871711],\n",
       "       [-0.70576986,  1.40375139],\n",
       "       [-1.29996338,  0.50496393],\n",
       "       [-0.30964085,  0.04107362],\n",
       "       [-0.11157634,  0.01208048],\n",
       "       [-0.30964085, -0.88670699],\n",
       "       [ 0.8787462 , -1.3505973 ],\n",
       "       [-0.30964085,  2.24455257],\n",
       "       [ 0.97777845,  1.98361427],\n",
       "       [-1.20093113,  0.47597078],\n",
       "       [-1.29996338,  0.27301877],\n",
       "       [ 1.37390747,  1.98361427],\n",
       "       [ 1.27487521, -1.3505973 ],\n",
       "       [-0.30964085, -0.27785096],\n",
       "       [-0.50770535,  1.25878567],\n",
       "       [-0.80480212,  1.08482681],\n",
       "       [ 0.97777845, -1.06066585],\n",
       "       [ 0.28455268,  0.30201192],\n",
       "       [ 0.97777845,  0.76590222],\n",
       "       [-0.70576986, -1.49556302],\n",
       "       [-0.70576986,  0.04107362],\n",
       "       [ 0.48261718,  1.72267598],\n",
       "       [ 2.06713324,  0.18603934],\n",
       "       [-1.99318916, -0.74174127],\n",
       "       [-0.21060859,  1.40375139],\n",
       "       [ 0.38358493,  0.59194336],\n",
       "       [ 0.8787462 , -1.14764529],\n",
       "       [-1.20093113, -0.77073441],\n",
       "       [ 0.18552042,  0.24402563],\n",
       "       [ 0.77971394, -0.30684411],\n",
       "       [ 2.06713324, -0.79972756],\n",
       "       [ 0.77971394,  0.12805305],\n",
       "       [-0.30964085,  0.6209365 ],\n",
       "       [-1.00286662, -0.30684411],\n",
       "       [ 0.18552042, -0.3648304 ],\n",
       "       [ 2.06713324,  2.12857999],\n",
       "       [ 1.86906873, -1.26361786],\n",
       "       [ 1.37390747, -0.91570013],\n",
       "       [ 0.8787462 ,  1.25878567],\n",
       "       [ 1.47293972,  2.12857999],\n",
       "       [-0.30964085, -1.23462472],\n",
       "       [ 1.96810099,  0.91086794],\n",
       "       [ 0.68068169, -0.71274813],\n",
       "       [-1.49802789,  0.35999821],\n",
       "       [ 0.77971394, -1.3505973 ],\n",
       "       [ 0.38358493, -0.13288524],\n",
       "       [-1.00286662,  0.41798449],\n",
       "       [-0.01254409, -0.30684411],\n",
       "       [-1.20093113,  0.41798449],\n",
       "       [-0.90383437, -1.20563157],\n",
       "       [-0.11157634,  0.04107362],\n",
       "       [-1.59706014, -0.42281668],\n",
       "       [ 0.97777845, -1.00267957],\n",
       "       [ 1.07681071, -1.20563157],\n",
       "       [-0.01254409, -0.13288524],\n",
       "       [-1.10189888, -1.52455616],\n",
       "       [ 0.77971394, -1.20563157],\n",
       "       [ 0.97777845,  2.07059371],\n",
       "       [-1.20093113, -1.52455616],\n",
       "       [-0.30964085,  0.79489537],\n",
       "       [ 0.08648817, -0.30684411],\n",
       "       [-1.39899564, -1.23462472],\n",
       "       [-0.60673761, -1.49556302],\n",
       "       [ 0.77971394,  0.53395707],\n",
       "       [-0.30964085, -0.33583725],\n",
       "       [ 1.77003648, -0.27785096],\n",
       "       [ 0.8787462 , -1.03167271],\n",
       "       [ 0.18552042,  0.07006676],\n",
       "       [-0.60673761,  0.8818748 ],\n",
       "       [-1.89415691, -1.40858358],\n",
       "       [-1.29996338,  0.59194336],\n",
       "       [-0.30964085,  0.53395707],\n",
       "       [-1.00286662, -1.089659  ],\n",
       "       [ 1.17584296, -1.43757673],\n",
       "       [ 0.18552042, -0.30684411],\n",
       "       [ 1.17584296, -0.74174127],\n",
       "       [-0.30964085,  0.07006676],\n",
       "       [ 0.18552042,  2.09958685],\n",
       "       [ 0.77971394, -1.089659  ],\n",
       "       [ 0.08648817,  0.04107362],\n",
       "       [-1.79512465,  0.12805305],\n",
       "       [-0.90383437,  0.1570462 ],\n",
       "       [-0.70576986,  0.18603934],\n",
       "       [ 0.8787462 , -1.29261101],\n",
       "       [ 0.18552042, -0.24885782],\n",
       "       [-0.4086731 ,  1.22979253],\n",
       "       [-0.01254409,  0.30201192],\n",
       "       [ 0.38358493,  0.1570462 ],\n",
       "       [ 0.8787462 , -0.65476184],\n",
       "       [ 0.08648817,  0.1570462 ],\n",
       "       [-1.89415691, -1.29261101],\n",
       "       [-0.11157634,  0.30201192],\n",
       "       [-0.21060859, -0.27785096],\n",
       "       [ 0.28455268, -0.50979612],\n",
       "       [-0.21060859,  1.6067034 ],\n",
       "       [ 0.97777845, -1.17663843],\n",
       "       [-0.21060859,  1.63569655],\n",
       "       [ 1.27487521,  1.8676417 ],\n",
       "       [-1.10189888, -0.3648304 ],\n",
       "       [-0.01254409,  0.04107362],\n",
       "       [ 0.08648817, -0.24885782],\n",
       "       [-1.59706014, -1.23462472],\n",
       "       [-0.50770535, -0.27785096],\n",
       "       [ 0.97777845,  0.12805305],\n",
       "       [ 1.96810099, -1.3505973 ],\n",
       "       [ 1.47293972,  0.07006676],\n",
       "       [-0.60673761,  1.37475825],\n",
       "       [ 1.57197197,  0.01208048],\n",
       "       [-0.80480212,  0.30201192],\n",
       "       [ 1.96810099,  0.73690908],\n",
       "       [-1.20093113, -0.50979612],\n",
       "       [ 0.68068169,  0.27301877],\n",
       "       [-1.39899564, -0.42281668],\n",
       "       [ 0.18552042,  0.1570462 ],\n",
       "       [-0.50770535, -1.20563157],\n",
       "       [ 0.58164944,  2.01260742],\n",
       "       [-1.59706014, -1.49556302],\n",
       "       [-0.50770535, -0.53878926],\n",
       "       [ 0.48261718,  1.83864855],\n",
       "       [-1.39899564, -1.089659  ],\n",
       "       [ 0.77971394, -1.37959044],\n",
       "       [-0.30964085, -0.42281668],\n",
       "       [ 1.57197197,  0.99784738],\n",
       "       [ 0.97777845,  1.43274454],\n",
       "       [-0.30964085, -0.48080297],\n",
       "       [-0.11157634,  2.15757314],\n",
       "       [-1.49802789, -0.1038921 ],\n",
       "       [-0.11157634,  1.95462113],\n",
       "       [-0.70576986, -0.33583725],\n",
       "       [-0.50770535, -0.8287207 ],\n",
       "       [ 0.68068169, -1.37959044],\n",
       "       [-0.80480212, -1.58254245],\n",
       "       [-1.89415691, -1.46656987],\n",
       "       [ 1.07681071,  0.12805305],\n",
       "       [ 0.08648817,  1.51972397],\n",
       "       [-0.30964085,  0.09905991],\n",
       "       [ 0.08648817,  0.04107362],\n",
       "       [-1.39899564, -1.3505973 ],\n",
       "       [ 0.28455268,  0.07006676],\n",
       "       [-0.90383437,  0.38899135],\n",
       "       [ 1.57197197, -1.26361786],\n",
       "       [-0.30964085, -0.74174127],\n",
       "       [-0.11157634,  0.1570462 ],\n",
       "       [-0.90383437, -0.65476184],\n",
       "       [-0.70576986, -0.04590581],\n",
       "       [ 0.38358493, -0.45180983],\n",
       "       [-0.80480212,  1.89663484],\n",
       "       [ 1.37390747,  1.28777882],\n",
       "       [ 1.17584296, -0.97368642],\n",
       "       [ 1.77003648,  1.83864855],\n",
       "       [-0.90383437, -0.24885782],\n",
       "       [-0.80480212,  0.56295021],\n",
       "       [-1.20093113, -1.5535493 ],\n",
       "       [-0.50770535, -1.11865214],\n",
       "       [ 0.28455268,  0.07006676],\n",
       "       [-0.21060859, -1.06066585],\n",
       "       [ 1.67100423,  1.6067034 ],\n",
       "       [ 0.97777845,  1.78066227],\n",
       "       [ 0.28455268,  0.04107362],\n",
       "       [-0.80480212, -0.21986468],\n",
       "       [-0.11157634,  0.07006676],\n",
       "       [ 0.28455268, -0.19087153],\n",
       "       [ 1.96810099, -0.65476184],\n",
       "       [-0.80480212,  1.3457651 ],\n",
       "       [-1.79512465, -0.59677555],\n",
       "       [-0.11157634,  0.12805305],\n",
       "       [ 0.28455268, -0.30684411],\n",
       "       [ 1.07681071,  0.56295021],\n",
       "       [-1.00286662,  0.27301877],\n",
       "       [ 1.47293972,  0.35999821],\n",
       "       [ 0.18552042, -0.3648304 ],\n",
       "       [ 2.1661655 , -1.03167271],\n",
       "       [-0.30964085,  1.11381995],\n",
       "       [-1.6960924 ,  0.07006676],\n",
       "       [-0.01254409,  0.04107362],\n",
       "       [ 0.08648817,  1.05583366],\n",
       "       [-0.11157634, -0.3648304 ],\n",
       "       [-1.20093113,  0.07006676],\n",
       "       [-0.30964085, -1.3505973 ],\n",
       "       [ 1.57197197,  1.11381995],\n",
       "       [-0.80480212, -1.52455616],\n",
       "       [ 0.08648817,  1.8676417 ],\n",
       "       [-0.90383437, -0.77073441],\n",
       "       [-0.50770535, -0.77073441],\n",
       "       [-0.30964085, -0.91570013],\n",
       "       [ 0.28455268, -0.71274813],\n",
       "       [ 0.28455268,  0.07006676],\n",
       "       [ 0.08648817,  1.8676417 ],\n",
       "       [-1.10189888,  1.95462113],\n",
       "       [-1.6960924 , -1.5535493 ],\n",
       "       [-1.20093113, -1.089659  ],\n",
       "       [-0.70576986, -0.1038921 ],\n",
       "       [ 0.08648817,  0.09905991],\n",
       "       [ 0.28455268,  0.27301877],\n",
       "       [ 0.8787462 , -0.5677824 ],\n",
       "       [ 0.28455268, -1.14764529],\n",
       "       [-0.11157634,  0.67892279],\n",
       "       [ 2.1661655 , -0.68375498],\n",
       "       [-1.29996338, -1.37959044],\n",
       "       [-1.00286662, -0.94469328],\n",
       "       [-0.01254409, -0.42281668],\n",
       "       [-0.21060859, -0.45180983],\n",
       "       [-1.79512465, -0.97368642],\n",
       "       [ 1.77003648,  0.99784738],\n",
       "       [ 0.18552042, -0.3648304 ],\n",
       "       [ 0.38358493,  1.11381995],\n",
       "       [-1.79512465, -1.3505973 ],\n",
       "       [ 0.18552042, -0.13288524],\n",
       "       [ 0.8787462 , -1.43757673],\n",
       "       [-1.99318916,  0.47597078],\n",
       "       [-0.30964085,  0.27301877],\n",
       "       [ 1.86906873, -1.06066585],\n",
       "       [-0.4086731 ,  0.07006676],\n",
       "       [ 1.07681071, -0.88670699],\n",
       "       [-1.10189888, -1.11865214],\n",
       "       [-1.89415691,  0.01208048],\n",
       "       [ 0.08648817,  0.27301877],\n",
       "       [-1.20093113,  0.33100506],\n",
       "       [-1.29996338,  0.30201192],\n",
       "       [-1.00286662,  0.44697764],\n",
       "       [ 1.67100423, -0.88670699],\n",
       "       [ 1.17584296,  0.53395707],\n",
       "       [ 1.07681071,  0.53395707],\n",
       "       [ 1.37390747,  2.331532  ],\n",
       "       [-0.30964085, -0.13288524],\n",
       "       [ 0.38358493, -0.45180983],\n",
       "       [-0.4086731 , -0.77073441],\n",
       "       [-0.11157634, -0.50979612],\n",
       "       [ 0.97777845, -1.14764529],\n",
       "       [-0.90383437, -0.77073441],\n",
       "       [-0.21060859, -0.50979612],\n",
       "       [-1.10189888, -0.45180983],\n",
       "       [-1.20093113,  1.40375139]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = sc_x.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.54748976,  0.5130727 ],\n",
       "       [ 0.15442019, -0.61825566],\n",
       "       [-0.10879604,  0.14615539],\n",
       "       [-0.54748976,  0.26846116],\n",
       "       [-0.10879604, -0.61825566],\n",
       "       [-0.81070599, -1.53554892],\n",
       "       [-0.45975102, -1.68843113],\n",
       "       [-0.0210573 ,  2.25592989],\n",
       "       [-1.60035469, -0.0678797 ],\n",
       "       [ 0.94406888, -0.83229075],\n",
       "       [-0.54748976, -0.6488321 ],\n",
       "       [-0.72296725, -0.46537345],\n",
       "       [ 0.06668145, -0.46537345],\n",
       "       [ 0.24215893,  0.20730828],\n",
       "       [-1.4248772 ,  0.48249625],\n",
       "       [-0.37201227,  1.43036596],\n",
       "       [ 0.06668145,  0.20730828],\n",
       "       [-1.51261594,  0.45191981],\n",
       "       [ 1.64597884,  1.8278597 ],\n",
       "       [-0.10879604, -1.47439603],\n",
       "       [-0.10879604, -0.70998498],\n",
       "       [ 0.94406888,  2.25592989],\n",
       "       [ 0.41763642, -0.58767922],\n",
       "       [ 0.94406888,  1.06344865],\n",
       "       [-1.16166097, -1.29093738],\n",
       "       [ 1.11954637,  2.16420057],\n",
       "       [-0.72296725,  0.5130727 ],\n",
       "       [-0.63522851,  0.2990376 ],\n",
       "       [ 0.06668145, -0.25133835],\n",
       "       [-0.37201227,  0.48249625],\n",
       "       [-1.33713846,  0.54364914],\n",
       "       [ 0.06668145,  0.26846116],\n",
       "       [ 1.82145632, -0.31249124],\n",
       "       [ 0.06668145, -0.52652633],\n",
       "       [-1.07392223, -0.37364412],\n",
       "       [-1.60035469, -0.55710277],\n",
       "       [-1.24939971,  0.32961404],\n",
       "       [-0.19653479, -0.83229075],\n",
       "       [-0.45975102, -1.10747873],\n",
       "       [ 1.11954637, -1.04632585],\n",
       "       [-0.81070599,  0.54364914],\n",
       "       [ 0.41763642, -0.55710277],\n",
       "       [-0.81070599,  0.42134337],\n",
       "       [-0.10879604, -1.53554892],\n",
       "       [ 0.59311391,  1.27748375],\n",
       "       [-0.81070599, -0.37364412],\n",
       "       [ 0.06668145,  0.2990376 ],\n",
       "       [ 1.3827626 ,  0.60480202],\n",
       "       [-0.89844474, -1.2297845 ],\n",
       "       [ 1.11954637,  0.48249625],\n",
       "       [ 1.82145632,  1.58324817],\n",
       "       [-0.19653479, -1.38266671],\n",
       "       [-0.10879604, -0.40422056],\n",
       "       [-0.19653479,  1.36921307],\n",
       "       [ 1.99693381,  0.54364914],\n",
       "       [ 0.7685914 , -1.16863161],\n",
       "       [-0.63522851,  0.39076693],\n",
       "       [-0.89844474,  0.2990376 ],\n",
       "       [ 1.11954637, -1.29093738],\n",
       "       [-1.16166097, -1.53554892],\n",
       "       [-0.37201227, -1.5967018 ],\n",
       "       [ 2.08467255, -0.86286719],\n",
       "       [-1.51261594,  0.17673183],\n",
       "       [-0.0210573 ,  0.87999   ],\n",
       "       [-1.51261594, -1.35209027],\n",
       "       [ 2.08467255,  0.39076693],\n",
       "       [-1.07392223,  0.57422558],\n",
       "       [-0.81070599, -0.37364412],\n",
       "       [ 0.32989768, -0.70998498],\n",
       "       [ 0.50537516, -0.00672682],\n",
       "       [-0.37201227,  2.43938854],\n",
       "       [-0.10879604,  0.20730828],\n",
       "       [-1.24939971, -0.22076191],\n",
       "       [ 0.7685914 , -1.47439603],\n",
       "       [-0.81070599,  0.57422558],\n",
       "       [-1.60035469,  0.36019049],\n",
       "       [ 0.50537516,  0.26846116],\n",
       "       [ 0.32989768, -0.31249124],\n",
       "       [ 1.47050135, -1.10747873],\n",
       "       [ 0.94406888,  1.12460154],\n",
       "       [ 1.90919507,  2.25592989],\n",
       "       [ 1.99693381,  0.39076693],\n",
       "       [-1.07392223, -0.46537345],\n",
       "       [-0.89844474, -1.07690229],\n",
       "       [ 1.90919507, -0.98517296],\n",
       "       [ 0.50537516,  0.2990376 ],\n",
       "       [ 0.32989768,  0.14615539],\n",
       "       [ 1.99693381,  1.8278597 ],\n",
       "       [ 0.85633014, -0.89344364],\n",
       "       [ 0.41763642, -0.31249124],\n",
       "       [ 0.50537516, -0.19018547],\n",
       "       [ 0.06668145,  2.31708278],\n",
       "       [-1.16166097, -0.67940854],\n",
       "       [-0.98618348, -1.13805517],\n",
       "       [-1.07392223,  0.42134337],\n",
       "       [-0.81070599,  0.78826068],\n",
       "       [-1.16166097, -0.22076191],\n",
       "       [ 1.03180763, -1.13805517],\n",
       "       [ 1.03180763,  0.60480202],\n",
       "       [ 0.50537516,  1.03287221]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Initializing Logistic Regression Model and Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a popular algorithm used for binary classification tasks, where the goal is to predict the probability of an instance belonging to a particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model\n",
    "classifier = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the test set results and calculating the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained using x_train and the corresponding target variable values y_train, we can use the trained model to make predictions on new, unseen data. To do so, we feed the test set (x_test) into the trained model, which generates predicted values for the target variable, denoted as y_pred. By comparing y_pred with the actual values of y_test, we can evaluate the model's performance and assess how well it generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " y_test( the actual values) and y_pred (the targeted value return by the classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91        68\n",
      "           1       0.83      0.75      0.79        32\n",
      "\n",
      "    accuracy                           0.87       100\n",
      "   macro avg       0.86      0.84      0.85       100\n",
      "weighted avg       0.87      0.87      0.87       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculate performance metrics\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix is a summary of prediction results on a classification problem.\n",
    "\n",
    "A confusion matrix is a matrix that summarizes the performance of a machine learning model on a set of test data.\n",
    "\n",
    "The matrix displays the number of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) produced by the model on the test data.\n",
    "\n",
    "For binary classification, the matrix will be of a 2X2 table, For multi-class classification, the matrix shape will be equal to the number of classes i.e for n classes it will be nXn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[63,  5],\n",
       "       [ 8, 24]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion Matrix')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAEICAYAAAAeFzyKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVwklEQVR4nO3df7RVdZ3/8ef73oui+RMURM0fFVjmjDZDrtQyjVGxnGBmMkfLQQfj6ypn7KtOYTPTYE0trMmv9V2NhTFKYhQ2okz+SL4U35mcUlDRcjApK0LugKKiBqLAe/44G9YR4Z77a99z7ub5YO11ztl7n895Hxa87ud+9mfvHZmJJKk8bc0uQJKqzqCVpJIZtJJUMoNWkkpm0EpSyQxaSSqZQattImKPiPi3iFgXEbf0oZ0PRcQ9/VlbM0TEXRExqdl1aPAzaAehiDgvIpZExIsR0VkEwjv7oekPACOB4Zl5dm8bycybM/P0fqjnVSLilIjIiLh1u/XHFusXdbOdaRExu9F+mXlmZs7qZbnSNgbtIBMRlwHXAp+nFoqHAf8MTOiH5g8HHs/MTf3QVlmeAk6MiOF16yYBj/fXB0SN/zfUfzLTZZAswL7Ai8DZXeyzO7UgXlUs1wK7F9tOAVYClwNrgE7gwmLbVcDLwCvFZ0wGpgGz69o+Akigo3h9AfAE8ALwK+BDdet/VPe+E4HFwLri8cS6bYuAzwL3Fu3cAxywk++2tf6vAR8r1rUX6z4NLKrb98vAb4HngQeAdxXrx2/3PR+uq+NzRR0bgDcV6y4qtl8HfLeu/auBhUA0+9+FS+sv/tQeXE4AhgLzutjnb4F3AMcBxwLHA39Xt/0gaoF9CLUw/WpE7J+Z/0Ctl/ydzNwrM2d2VUhEvA74CnBmZu5NLUyX7mC/YcAdxb7DgWuAO7brkZ4HXAiMAHYDrujqs4FvAn9RPD8DeJTaD5V6i6n9HQwDvgXcEhFDM/Pu7b7nsXXvOR+YAuwN/Ga79i4Hfj8iLoiId1H7u5uUmZ7DroYM2sFlOPB0dv2r/YeAz2Tmmsx8ilpP9fy67a8U21/JzDup9eqO6mU9W4BjImKPzOzMzEd3sM/7gOWZeVNmbsrMOcBjwB/X7XNDZj6emRuAudQCcqcy8z+BYRFxFLXA/eYO9pmdmWuLz/wStZ5+o+95Y2Y+Wrznle3aWw98mNoPitnAX2XmygbtSYBBO9isBQ6IiI4u9jmYV/fGflOs29bGdkG9Htirp4Vk5u+Ac4CLgc6IuCMi3tyNerbWdEjd6//uRT03AZcAp7KDHn5EXB4Ry4oZFM9R68Uf0KDN33a1MTPvpzZUEtR+IEjdYtAOLj8GXgImdrHPKmoHtbY6jNf+Wt1dvwP2rHt9UP3GzPx+Zp4GjKLWS72+G/VsrenJXta01U3AR4E7i97mNsWv9p8EPgjsn5n7URsfjq2l76TNLocBIuJj1HrGq4BP9Lpy7XIM2kEkM9dRO+jz1YiYGBF7RsSQiDgzIr5Q7DYH+LuIODAiDij2bziVaSeWAidHxGERsS9w5dYNETEyIt5fjNVupDYEsXkHbdwJjCmmpHVExDnA0cD3elkTAJn5K+Dd1Makt7c3sInaDIWOiPg0sE/d9tXAET2ZWRARY4B/pDZ8cD7wiYg4rnfVa1dj0A4ymXkNcBm1A1xPUft19xLgtmKXfwSWAI8APwUeLNb15rMWAN8p2nqAV4djG7UDRKuAZ6iF3kd30MZa4Kxi37XUeoJnZebTvalpu7Z/lJk76q1/H7iL2pSv31D7LaB+WGDryRhrI+LBRp9TDNXMBq7OzIczcznwKeCmiNi9L99Bu4bwoKkklcserSSVzKCVpJIZtJJUMoNWkkrW1cT3frHHYed6tE2vsWHFVc0uQS1pTDTep2s9yZwNK+b0+fO6wx6tJJWs9B6tJA2kVrzCpUErqVLaurwUSHO0XkWS1Af2aCWpZBEDcnyrRwxaSRVjj1aSStWKQwetV5Ek9UFEW7eXxm3FfhHx3Yh4rLiQ/AkRMSwiFkTE8uJx/0btGLSSKqUtOrq9dMOXgbsz883U7sG3DJgKLMzM0dRu0Dm1YU19+D6S1HL6q0cbEfsAJwMzATLz5cx8DpgAzCp2m0XXdzwBDFpJFdOPQwdvoHZx/Rsi4qGI+EZxR5GRmdkJUDyOaNSQQSupUqInfyKmRMSSumVKXVMdwB8A12Xm26jdQ6/hMMGOOOtAUqX0ZNZBZs4AZuxk80pgZWbeV7z+LrWgXR0RozKzMyJGAWsafY49WkmV0tbW0e2lK5n538BvI+KoYtU44L+A+cCkYt0k4PZGNdmjlVQx/dp//Cvg5ojYDXgCuLD4gLkRMRlYAZzdqBGDVlKl9OcJC5m5FBi7g03jetKOQSupUlrxzDCDVlKlRAseejJoJVWKPVpJKllbW3uzS3gNg1ZSpTh0IEklc+hAkkpm0EpSyRw6kKSSRYNTa5uh9SqSpD7w5oySVDKHDiSpZB4Mk6SyOXQgSSVrvQ6tQSupYtpaL2kNWknV0no5a9BKqpZ0jFaSStZ6OWvQSqqYttZLWoNWUrU4dCBJJWs3aCWpXPZoJalkrZezBq2kivFgmCSVrPVy1qCVVC3Z3nqnhhm0kqrFHq0klcxZB5JUMg+GSVLJ+jFnI+LXwAvAZmBTZo6NiGHAd4AjgF8DH8zMZ7tqp/VGjSWpLyK6v3TPqZl5XGaOLV5PBRZm5mhgYfG6SwatpGppj+4vvTMBmFU8nwVMbPQGg1ZStfSgRxsRUyJiSd0yZbvWErgnIh6o2zYyMzsBiscRjUpyjFZStfSgo5qZM4AZXexyUmauiogRwIKIeKw3JRm0Jdp3nz257gtTOHrMoWTCxX/zdc449TjOOn0sW7Zs4am1zzPl8q/RubrLcXRV2HveM5nXvW4P2traaG9v59Zb/0+zSxr0sh9nHWTmquJxTUTMA44HVkfEqMzsjIhRwJpG7Ri0JfqnaZO4Z9HDnHfxtQwZ0s6ee+zOfz2+ks986RYAPnrhGVx56Z/y15+a2eRK1UyzZn2OYcP2bXYZ1dFP82gj4nVAW2a+UDw/HfgMMB+YBEwvHm9v1FbDoI2IN1Mb/D2E2njFKmB+Zi7r9TfYBey91x688/g385HLrgPglVc2s+6V9a/aZ889h5KZzShPqq7+69COBOZFLbg7gG9l5t0RsRiYGxGTgRXA2Y0a6jJoI+KTwLnAt4H7i9WHAnMi4tuZOb3336HajjxsBE8/8zwzvnQxv/eWw3nop09wxbRvsn7DRqb9zQf50J+dzLoX1jP+nM82u1Q12eTJnyYiOOec8ZxzzvhmlzP49dO1DjLzCeDYHaxfC4zrSVuNKpoMvD0zp2fm7GKZTm2cYvLO3lR/JG/Ti7/oST2V0dHRznHHHMn1Ny3ghPdeyfoNG7nio+8HYNoX5zL6HZfw7dvu5eILzmhypWqmOXO+wLx5X+b666dx8813sHjxz5pd0uAXPVgGSKOg3QIcvIP1o4ptO5SZMzJzbGaO7djrTX2pb9B6snMtT3Y+w+KlvwRg3p33cdwxR75qn7m33cvEM49vRnlqESNHDgdg+PD9OO20E3jkkcebXFEFtEX3l4EqqcH2jwMLI+KuiJhRLHdTOxvi0tKrG8RWP7WOlZ1rGf2GUQCcctIxPLZ8JW884qBt+7zvtD/k8V+ualaJarL161/ixRfXb3t+770PMXr04U2uqgJaMGi7HKMtBn7HUBsqOIRaZ3slsDgzNw9AfYPaZZ++kRu+cgm7Deng1ytWM+WKr3Pd1R9h9BsPZsuWZMWTT/HXVzrjYFe1du1zfOxjnwNg8+bNnHXWuzn55D9sclWDX7beNWWIso9673HYuR5W12tsWHFVs0tQSxrT55h8w//6125nzhNf/7MBiWXn0UqqFi+TKEkla8EruBi0kqrFOyxIUskcOpCkcqU9WkkqWYdBK0nlskcrSSVzjFaSStZ6OWvQSqqW/rzDQn8xaCVVi0ErSSXr/W3ES2PQSqoWZx1IUskcOpCkkhm0klQuT8GVpLJ5MEySSubQgSSVzKCVpJK1Xs4atJKqxVNwJalszjqQpJK14KyDFrxfpCT1Xltb95fuiIj2iHgoIr5XvB4WEQsiYnnxuH/Dmvr2lSSptUR0f+mmS4Flda+nAgszczSwsHjdJYNWUqX0Z9BGxKHA+4Bv1K2eAMwqns8CJjZqxzFaSZUS/Xsw7FrgE8DedetGZmYnQGZ2RsSIRo3Yo5VUKT0Zo42IKRGxpG6ZsrWdiDgLWJOZD/S1Jnu0kioletB9zMwZwIydbD4JeH9EvBcYCuwTEbOB1RExqujNjgLWNPoce7SSKqW/xmgz88rMPDQzjwD+HPhBZn4YmA9MKnabBNzeqCZ7tJIqZQBODJsOzI2IycAK4OxGbzBoJVVKGSeGZeYiYFHxfC0wrifvN2glVUoLnoFr0EqqlrYWPAXXoJVUKfZoJalkBq0klcyglaSSteB1vw1aSdVij1aSSuasA0kqmT1aSSqZQStJJTNoJalkzjqQpJK1tTe7gtcyaCVVikMHklSyfr5nWL8waCVVSgvmrEErqVp2yaB97lf/u+yP0CA08+e/anYJakGTjxrT5zZ2yaCVpIHU0YK3nDVoJVVKW2SzS3gNg1ZSpXjCgiSVrAVHDgxaSdXi0IEklcyhA0kqWYdBK0nlCocOJKlcDh1IUsmcdSBJJWvFWQetGP6S1Gsd0f2lKxExNCLuj4iHI+LRiLiqWD8sIhZExPLicf9GNRm0kiqlLbq/NLAReE9mHgscB4yPiHcAU4GFmTkaWFi87rqmPn0jSWoxbZHdXrqSNS8WL4cUSwITgFnF+lnAxIY19frbSFIL6kmPNiKmRMSSumVKfVsR0R4RS4E1wILMvA8YmZmdAMXjiEY1eTBMUqX0pPeYmTOAGV1s3wwcFxH7AfMi4pje1GTQSqqUMmYdZOZzEbEIGA+sjohRmdkZEaOo9Xa7rqnfK5KkJupo6/7SlYg4sOjJEhF7AH8EPAbMByYVu00Cbm9YUx++jyS1nH7sPY4CZkVEe9Hs3Mz8XkT8GJgbEZOBFcDZjRoyaCVVSn8NHWTmI8DbdrB+LTCuJ20ZtJIqxWsdSFLJWvHAk0ErqVLs0UpSydrbWu+iMgatpEpx6ECSStaKl0k0aCVVimO0klQyg1aSSjbEoQNJKpc9WkkqmUErSSVrN2glqVz2aCWpZM6jlaSSDbFHK0nlcuhAkkrm0IEklcxZB5JUMocOJKlkje5u2wwGraRKaXeMVpLK1YIdWoNWUrU4RitJJTNoJalkjtFKUsmcdSBJJXPoQJJK1opnhrVgJ1uSeq8tsttLVyLi9RHxw4hYFhGPRsSlxfphEbEgIpYXj/s3qske7QC5adZd3Prd/w8Bo8e8ns9+7iPsvvtuzS5LA+j5p57ljmtv4nfPvkBEcOwZJzL2/ads237/vIUsuuF2Lpn9efbcZ6/mFTrI9WPvcRNweWY+GBF7Aw9ExALgAmBhZk6PiKnAVOCTA1STdmb16me4efY9zLnlM8ybP50tm7dw950/aXZZGmBt7W2c+pd/wkX//Ld8+IuX8dCd/8HTKzqBWgj/eunP2efAhp0jNdAW3V+6kpmdmflg8fwFYBlwCDABmFXsNguY2LCmPnwf9cDmzVvY+NLLbNq0mZdeepkDR/gfalez17B9OeiNrwdg9z2HMvzQkby4dh0AP5h5K6dcMAGiBQcYB5khbdntpbsi4gjgbcB9wMjM7IRaGAMjGr3foYMBMHLkMCZd+F5OH/dxhg7djRNOPIYTT/q9ZpelJlq3ei2rn3iSUUcdzvL7fsrew/djxJGHNLusSujJrIOImAJMqVs1IzNnbLfPXsC/Ah/PzOejFz8Me92jjYgLu9g2JSKWRMSSb1w/r7cfURnPr/sdP/zBA9y14Br+36KvsGHDRr43/95ml6UmeXnDRm6bPpNxF/0pbe3t/OSWe3jnee9tdlmV0ZOhg8yckZlj65btQ3YItZC9OTNvLVavjohRxfZRwJqGNfXh+1y1sw31xV/0kT/pw0dUw09+/DMOPeRAhg3bhyFDOhh32ttZunR5s8tSE2zetJnbps/k6HePZcyJx/Jc59OsW72WGy69mq9dNI0Xnn6OWR//Ii8++3yzSx202nqwdCVqXdeZwLLMvKZu03xgUvF8EnB7o5q6HDqIiEd2tgkY2ahx1Rw0ajiPPPxLNmzYyNChu3HfTx7lrW89stllaYBlJnf/328x/NCRvH3iewA48IiDueSmz2/b52sXTeMvrrnCWQd90I/D3CcB5wM/jYilxbpPAdOBuRExGVgBnN2ooUZjtCOBM4Bnt1sfwH/2oOBd2u8f+yb+6PS3c84H/p729jbe8pYj+MAHT212WRpgTy57gkd/uJgDDz+YGy+9GoB3nX8Wbxz71iZXVi39dWZYZv6IWtbtyLietBWZOz/yFhEzgRuKD9x+27cy87xGH7Bx8/2td4UHNd3sX2z/s1uCyUed0eeYfPDpO7qdOX9wwPsGZJpHlz3azJzcxbaGIStJAy28epcklasVZyIbtJIqpRXP+TBoJVVKC+asQSupWlrxMokGraRKcehAkkrWgjlr0EqqFoNWkkrmPcMkqWQtmLMGraRqaXQvsGYwaCVVirMOJKlkrXh/LoNWUqXYo5WkkrVgzhq0kqrF6V2SVDKDVpJK1oI5a9BKqhbvsCBJJbNHK0klc3qXJJWsvdkF7IBBK6lS7NFKUulaL2kNWkmVEgatJJUrovUuK2PQSqoYe7SSVKpowQsltl5FktQHEW3dXhq3Ff8SEWsi4md164ZFxIKIWF487t+oHYNWUsVED5aGbgTGb7duKrAwM0cDC4vXXTJoJVVK9OBPI5n578Az262eAMwqns8CJjZqx6CVVCk9CdqImBIRS+qWKd34iJGZ2QlQPI5o9AYPhkmqlIjun4SbmTOAGeVVU2OPVlLF9OsY7Y6sjohRAMXjmkZvMGglVUp/jtHuxHxgUvF8EnB7ozc4dCCpYvqv/xgRc4BTgAMiYiXwD8B0YG5ETAZWAGc3aseglVQp/Xmtg8w8dyebxvWkHYNWUqVEC14n0aCVVCnRgpf+NmglVYw9WkkqlUMHklQ6g1aSStWKl0k0aCVVjD1aSSpVm7eykaSyGbSSVCrvgitJpTNoJalUzqOVpJK14im4kZnNrmGXERFTiiu6S9v476L6Wu/wXLV1535E2vX476LiDFpJKplBK0klM2gHluNw2hH/XVScB8MkqWT2aCWpZAatJJXMoB0gETE+In4eEb+IiKnNrkfNFxH/EhFrIuJnza5F5TJoB0BEtANfBc4EjgbOjYijm1uVWsCNwPhmF6HyGbQD43jgF5n5RGa+DHwbmNDkmtRkmfnvwDPNrkPlM2gHxiHAb+teryzWSdoFGLQDY0eXE3JenbSLMGgHxkrg9XWvDwVWNakWSQPMoB0Yi4HREXFkROwG/Dkwv8k1SRogBu0AyMxNwCXA94FlwNzMfLS5VanZImIO8GPgqIhYGRGTm12TyuEpuJJUMnu0klQyg1aSSmbQSlLJDFpJKplBK0klM2glqWQGrSSV7H8AgcnG2nDkMK4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True,cmap='YlGnBu').set_title(\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binary classifier predicts all data instances of a test dataset as either positive or negative. This classification (or prediction) produces four outcomes â€“ true positive, true negative, false positive and false negative.\n",
    "\n",
    "True positive (TP): correct positive prediction\n",
    "\n",
    "False positive (FP): incorrect positive prediction\n",
    "\n",
    "True negative (TN): correct negative prediction\n",
    "\n",
    "False negative (FN): incorrect negative prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > True Positive : actually true predicted true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = cm[0,[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE POSITIVE :  [63]\n"
     ]
    }
   ],
   "source": [
    "print(\"TRUE POSITIVE : \",tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > False Positive : actually false predicted true [Type-1 Error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = cm[0,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALSE POSITIVE :  [5]\n"
     ]
    }
   ],
   "source": [
    "print(\"FALSE POSITIVE : \",fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > False Negative : actually true predicted false [Type-2 Error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = cm[1,[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALSE NEGATIVE :  [8]\n"
     ]
    }
   ],
   "source": [
    "print(\"FALSE NEGATIVE : \",fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > True Negative : actually false predicted false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = cm[1,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALSE NEGATIVE :  [24]\n"
     ]
    }
   ],
   "source": [
    "print(\"TRUE NEGATIVE : \",tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Accuracy using Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy (ACC) is calculated as the number of all correct predictions divided by the total number of the dataset. \n",
    "\n",
    "The best accuracy is 1.0, whereas the worst is 0.0. \n",
    "\n",
    "It can also be calculated by 1 â€“ ERR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (tp+tn)/(tp+fp+tn+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY : [87.]\n"
     ]
    }
   ],
   "source": [
    "print(\"ACCURACY :\",accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Error Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error rate is calculated as the number of all incorrect predictions divided by the total number of the dataset. \n",
    "\n",
    "The best error rate is 0.0, whereas the worst is 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = (fp+fn)/(tp+fp+tn+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR RATE : [13.]\n"
     ]
    }
   ],
   "source": [
    "print(\"ERROR RATE :\",error_rate*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision is calculated as the number of correct positive predictions divided by the total number of positive predictions.\n",
    "\n",
    "It is also called positive predictive value (PPV). \n",
    "\n",
    "The best precision is 1.0, whereas the worst is 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (tp)/(tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92647059])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION : [92.64705882]\n"
     ]
    }
   ],
   "source": [
    "print(\"PRECISION :\",precision*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall indicates the proportion of correctly identified positive instances out of all the actual positive instances.\n",
    "\n",
    "It is also called Sensitivity (SN) or true positive rate (TPR). \n",
    "\n",
    "The best sensitivity is 1.0, whereas the worst is 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = (tp)/(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88732394])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECALL : [88.73239437]\n"
     ]
    }
   ],
   "source": [
    "print(\"RECALL :\",recall*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## > Specify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specificity is calculated as the number of correct negative predictions divided by the total number of negatives. \n",
    "\n",
    "It is also called true negative rate (TNR). \n",
    "\n",
    "The best specificity is 1.0, whereas the worst is 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "specify = (tn)/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82758621])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPECIFY : [82.75862069]\n"
     ]
    }
   ],
   "source": [
    "print(\"SPECIFY :\",specify*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shravani Sajekar\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "plt.subplot(3,3,1)\n",
    "sns.regplot(y_test,y_pred, logistic=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
